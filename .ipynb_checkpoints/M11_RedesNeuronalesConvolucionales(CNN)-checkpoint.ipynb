{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28efa42-2b59-4a5b-ab79-f75bacc8aa7d",
   "metadata": {},
   "source": [
    "<h1> Marco Teórico: Módulo 11: Redes Neuronales Convolucionales (CNN) </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726798ab-a6d8-45d1-a9fb-97cf4f596d9d",
   "metadata": {},
   "source": [
    "#### 1. Introducción a las Redes Neuronales Convolucionales (CNN)\n",
    "\n",
    "Las **redes neuronales convolucionales** (CNN, por sus siglas en inglés) son una clase de redes neuronales profundas diseñadas específicamente para procesar datos con una estructura de cuadrícula, como las imágenes. Las CNN han demostrado ser muy efectivas en tareas de visión computacional, tales como la clasificación de imágenes, la detección de objetos y la segmentación. La principal diferencia entre las CNN y las redes neuronales tradicionales (**fully connected**) es que las CNN son capaces de capturar patrones espaciales locales gracias al uso de capas convolucionales y de pooling.\n",
    "\n",
    "#### 2. Capas de Convolución\n",
    "\n",
    "Las **capas convolucionales** son el núcleo de una CNN. Estas capas aplican **filtros** (o kernels) que se desplazan sobre la imagen para extraer características locales, como bordes, texturas y estructuras más complejas en etapas posteriores.\n",
    "\n",
    "**2.1 Operación de Convolución**\n",
    "\n",
    "La operación de convolución es una operación matemática en la que un filtro $K$ de tamaño $k \\times k$ se aplica a una imagen $I$  para generar una salida $S$. Matemáticamente, la convolución para una posición $(i,j)$  de la imagen puede expresarse como:\n",
    "\n",
    "$\n",
    "S(i,j) = (I * K)(i,j) = \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} I(i+m, j+n) \\cdot K(m,n)\n",
    "$\n",
    "\n",
    "Donde:\n",
    "- $ I(i,j) $ es la intensidad de píxel en la posición $ (i,j) $ de la imagen de entrada,\n",
    "- $ K(m,n) $ es el valor del kernel o filtro en la posición $ (m,n) $,\n",
    "- $ S(i,j) $ es el valor de la salida convolucional en la posición $ (i,j) $,\n",
    "- $ (*) $ denota la operación de convolución.\n",
    "\n",
    "**2.2 Parámetros: Stride y Padding**\n",
    "\n",
    "- **Stride (paso)**: El stride es el número de posiciones que se mueve el filtro sobre la imagen. Un stride más alto genera una salida de menor tamaño porque el filtro se mueve más lejos en cada paso. Si el stride es $ s $, entonces el tamaño de la salida $ S $ se calcula como:\n",
    "\n",
    "$\n",
    "S_{\\text{size}} = \\left( \\frac{I_{\\text{size}} - K_{\\text{size}}}{s} + 1 \\right)\n",
    "$\n",
    "\n",
    "- **Padding (relleno)**: Para evitar que las dimensiones de la imagen se reduzcan demasiado después de cada capa convolucional, se suele aplicar **padding**, que consiste en añadir ceros alrededor de los bordes de la imagen de entrada. El padding puede ser \"válido\" (sin padding) o \"same\" (con padding para mantener el tamaño de entrada).\n",
    "\n",
    "#### 3. Capas de Pooling\n",
    "\n",
    "Las **capas de pooling** se utilizan para reducir la dimensionalidad de las representaciones y, al mismo tiempo, retener las características más importantes. Esto también ayuda a reducir el riesgo de sobreajuste al hacer el modelo menos dependiente de pequeñas variaciones en la entrada.\n",
    "\n",
    "##### 3.1 Max Pooling\n",
    "\n",
    "El **max pooling** selecciona el valor máximo de una región definida por una ventana (por ejemplo, $ 2 \\times 2 $). Para una ventana $ 2 \\times 2 $, el max pooling se calcula como:\n",
    "\n",
    "$\n",
    "M(i,j) = \\max \\{ I(i+m, j+n) \\mid 0 \\leq m, n < 2 \\}\n",
    "$\n",
    "\n",
    "Donde $ M(i,j) $ es el valor máximo dentro de la ventana en la posición $(i,j)$.\n",
    "\n",
    "##### 3.2 Average Pooling\n",
    "\n",
    "El **average pooling** en cambio calcula el promedio de los valores dentro de la ventana:\n",
    "\n",
    "$\n",
    "A(i,j) = \\frac{1}{n^2} \\sum_{m=0}^{n-1} \\sum_{n=0}^{n-1} I(i+m, j+n)\n",
    "$\n",
    "\n",
    "Esta técnica es menos común que el max pooling, pero se usa en algunas arquitecturas.\n",
    "\n",
    "#### 4. Capas Fully Connected\n",
    "\n",
    "Las **capas fully connected** o completamente conectadas son similares a las utilizadas en redes neuronales tradicionales. En estas capas, cada neurona está conectada a todas las neuronas de la capa anterior. La salida de las capas convolucionales y de pooling se aplana en un vector de una sola dimensión, que luego se alimenta a una o varias capas fully connected para hacer la predicción final.\n",
    "\n",
    "La función de activación que comúnmente se usa en la capa de salida para problemas de clasificación es la **función softmax**, que convierte los valores de las neuronas en probabilidades normalizadas:\n",
    "\n",
    "$\n",
    "\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{C} e^{z_j}}\n",
    "$\n",
    "\n",
    "Donde:\n",
    "- $ z_i $ es el valor de activación de la neurona $ i $,\n",
    "- $ C $ es el número total de clases.\n",
    "\n",
    "#### 5. Data Augmentation\n",
    "\n",
    "El **data augmentation** es una técnica utilizada para aumentar artificialmente el tamaño del conjunto de datos mediante la creación de nuevas muestras a partir de las existentes mediante transformaciones como rotaciones, traslaciones, escalado y espejeo. Estas transformaciones ayudan a que la red sea más robusta a las variaciones y evitan el sobreajuste.\n",
    "\n",
    "Matemáticamente, si una imagen $ x $ sufre una transformación $ T $, el data augmentation genera una nueva imagen $ x' $ definida por:\n",
    "\n",
    "$\n",
    "x' = T(x)\n",
    "$\n",
    "\n",
    "Donde $T$ puede ser una transformación geométrica (rotación, escalado) o de color (ajuste de brillo, contraste).\n",
    "\n",
    "#### 6. Transfer Learning\n",
    "\n",
    "El **transfer learning** es una técnica en la cual se aprovechan modelos preentrenados en grandes conjuntos de datos (por ejemplo, ImageNet) para adaptarlos a una tarea específica. En lugar de entrenar la red desde cero, se utilizan los pesos preentrenados en las primeras capas y se ajustan las últimas capas para la tarea actual.\n",
    "\n",
    "Formalmente, si un modelo preentrenado se denota como $ f(x; \\theta_{\\text{pre}}) $, donde $ \\theta_{\\text{pre}} $ son los pesos preentrenados, el transfer learning consiste en mantener esos pesos en las primeras capas y ajustar solo los pesos $\\theta_{\\text{nuevo}}$ de las capas finales para la tarea específica:\n",
    "\n",
    "$\n",
    "y = f(x; \\theta_{\\text{pre}}) + g(x; \\theta_{\\text{nuevo}})\n",
    "$\n",
    "\n",
    "Donde $g(x; \\theta_{\\text{nuevo}})$ representa las capas recién entrenadas para la tarea de destino.\n",
    "\n",
    "#### 7. Función de Pérdida y Optimización\n",
    "\n",
    "La **función de pérdida** más comúnmente utilizada en tareas de clasificación es la **entropía cruzada**:\n",
    "\n",
    "$\n",
    "L = - \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{i,c} \\log \\hat{y}_{i,c}\n",
    "$\n",
    "\n",
    "Donde:\n",
    "- $ N $ es el número de muestras de entrenamiento,\n",
    "- $ C $ es el número de clases,\n",
    "- $ y_{i,c} $ es el valor verdadero $(0 o 1)$ para la clase $c$ de la muestra $i$,\n",
    "- $ \\hat{y}_{i,c} $ es la probabilidad predicha para la clase $c$.\n",
    "\n",
    "Los parámetros de la red se ajustan mediante **backpropagation**, una técnica que calcula los gradientes de la función de pérdida con respecto a los pesos y luego ajusta los pesos utilizando un algoritmo de optimización como **Adam** o **SGD**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bed3012-dec3-4983-b844-cc71c3e0f48c",
   "metadata": {},
   "source": [
    "<h1> Módulo 11: Redes Neuronales Convolucionales (CNN)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3190a2af-52cc-439a-8b18-8a08a4da1215",
   "metadata": {},
   "source": [
    "**Conceptos clave:**\n",
    "\n",
    "Redes neuronales convolucionales para visión computacional.\n",
    "    \n",
    "Capas de convolución, pooling y fully connected.\n",
    "    \n",
    "Data augmentation y Transfer Learning.\n",
    "\n",
    "**Proyecto: Clasificación avanzada de imágenes.**\n",
    "    \n",
    "Implementar un modelo CNN para clasificar imágenes en el dataset CIFAR-10 o Fashion MNIST, utilizando data augmentation y transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a54f17-5bd3-4319-8703-1022af3708ca",
   "metadata": {},
   "source": [
    "**Proyecto 1: CNN para Imágenes en Escala de Grises (Fashion MNIST)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8460479c-536a-4943-a4a6-cb6a68e13be1",
   "metadata": {},
   "source": [
    "**1. Preparar el Entorno**\n",
    "\n",
    "Primero, asegurémonos de tener las bibliotecas necesarias. Puedes instalar las bibliotecas requeridas usando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66f438c8-7d9e-486c-b5b6-521c9c061855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade tensorflow keras\n",
    "#!pip install scipy==1.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6cfe6e01-0434-44a9-a539-320be47289ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall keras tensorflow\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "117b0374-908e-4baf-ba81-4f590fa7f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c0627-4384-4968-abb6-3d58189ebae6",
   "metadata": {},
   "source": [
    "**2. Importar las Librerías**\n",
    "\n",
    "Vamos a importar las librerías necesarias para el proyecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "091ac64d-0416-423a-afb6-bdc8af8ce33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94ac26-d950-4167-a51c-7dd8020a8888",
   "metadata": {},
   "source": [
    "**3. Cargar el Dataset**\n",
    "\n",
    "Usaremos el dataset de Fashion MNIST, que está disponible en Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05a32988-0f9e-4aab-a830-081ec5120004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset de Fashion MNIST\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalizar las imágenes y ajustar el formato\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23525d01-153e-4dd0-bee4-f2b5c2c3d822",
   "metadata": {},
   "source": [
    "**4. Data Augmentation**\n",
    "\n",
    "Para mejorar la capacidad de generalización del modelo, usaremos data augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "746c5430-a1a3-4b98-9e0c-35a37a0066a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julio/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Construir un modelo CNN desde cero\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526efe70-c7a9-4141-8ad6-f597c4c8ed63",
   "metadata": {},
   "source": [
    "**5.  Entrenar el Modelo**\n",
    "\n",
    "Vamos a construir un modelo de red neuronal convolucional usando transfer learning con una red preentrenada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "559d4207-a4d2-4516-8466-420249db35f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julio/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  def workers(self):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 86ms/step - accuracy: 0.5304 - loss: 1.2744 - val_accuracy: 0.7394 - val_loss: 0.6819\n",
      "Epoch 2/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 87ms/step - accuracy: 0.7075 - loss: 0.7720 - val_accuracy: 0.7568 - val_loss: 0.6327\n",
      "Epoch 3/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 74ms/step - accuracy: 0.7474 - loss: 0.6693 - val_accuracy: 0.7939 - val_loss: 0.5437\n",
      "Epoch 4/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 71ms/step - accuracy: 0.7709 - loss: 0.6115 - val_accuracy: 0.7999 - val_loss: 0.5106\n",
      "Epoch 5/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 70ms/step - accuracy: 0.7834 - loss: 0.5815 - val_accuracy: 0.8319 - val_loss: 0.4573\n",
      "Epoch 6/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 68ms/step - accuracy: 0.7953 - loss: 0.5460 - val_accuracy: 0.8394 - val_loss: 0.4353\n",
      "Epoch 7/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 70ms/step - accuracy: 0.8063 - loss: 0.5160 - val_accuracy: 0.8421 - val_loss: 0.4236\n",
      "Epoch 8/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 66ms/step - accuracy: 0.8109 - loss: 0.5061 - val_accuracy: 0.8466 - val_loss: 0.4083\n",
      "Epoch 9/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 66ms/step - accuracy: 0.8183 - loss: 0.4886 - val_accuracy: 0.8447 - val_loss: 0.4263\n",
      "Epoch 10/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 73ms/step - accuracy: 0.8244 - loss: 0.4790 - val_accuracy: 0.8546 - val_loss: 0.4002\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(datagen.flow(train_images, train_labels, batch_size=64),\n",
    "                    epochs=10,\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bf253-cb33-47af-bb42-6a26480cb323",
   "metadata": {},
   "source": [
    "**Paso 6: Evaluar el modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "491f26a4-7d4d-425a-8b62-65d80cec94a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8555 - loss: 0.4085\n",
      "Accuracy en test: 0.8546000123023987\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el set de test\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Accuracy en test: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b10a1f-e420-46fe-a4da-263f2f3e2f50",
   "metadata": {},
   "source": [
    "**Proyecto 2: Clasificación Avanzada de Imágenes RGB (CIFAR-10)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67796a4d-b9cc-4041-a84f-ec41414ca078",
   "metadata": {},
   "source": [
    "**Paso 1: Importar librerías y cargar el dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7377a087-fdff-4887-b1a4-fea77559a1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Cargar dataset CIFAR-10\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Reescalar imágenes (de 0 a 255 a valores entre 0 y 1)\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08489289-4db5-45f4-8f57-da614e20f170",
   "metadata": {},
   "source": [
    "**Paso 2: Crear el generador de datos con aumentación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc87a211-2540-4e5d-8969-63e8e1698296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el generador de datos con aumentación\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Ajustar el generador a los datos de entrenamiento\n",
    "datagen.fit(train_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b25ab2c-6f02-40d7-b502-5843edeb7b67",
   "metadata": {},
   "source": [
    "**Paso 3: Cargar un modelo preentrenado con Transfer Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25b10c90-e3e3-45fb-bba4-67fed6509a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22741/3115286404.py:2: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Cargar MobileNetV2 preentrenado con pesos de ImageNet (se excluye la capa superior)\n",
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Congelar las capas del modelo base\n",
    "base_model.trainable = False\n",
    "\n",
    "# Crear el modelo completo agregando capas adicionales\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a437fbd-357f-49c8-9823-cf06fa29e7fd",
   "metadata": {},
   "source": [
    "**Paso 4: Entrenar el modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39bfb721-aa6a-4067-8993-17b8829450ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 124ms/step - accuracy: 0.2269 - loss: 2.1059 - val_accuracy: 0.2966 - val_loss: 1.9420\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 116ms/step - accuracy: 0.2818 - loss: 1.9632 - val_accuracy: 0.3106 - val_loss: 1.9141\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 115ms/step - accuracy: 0.2894 - loss: 1.9451 - val_accuracy: 0.3162 - val_loss: 1.8821\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 123ms/step - accuracy: 0.2963 - loss: 1.9300 - val_accuracy: 0.3245 - val_loss: 1.8703\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 114ms/step - accuracy: 0.2972 - loss: 1.9284 - val_accuracy: 0.3274 - val_loss: 1.8623\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 113ms/step - accuracy: 0.3049 - loss: 1.9128 - val_accuracy: 0.3269 - val_loss: 1.8568\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 124ms/step - accuracy: 0.3009 - loss: 1.9084 - val_accuracy: 0.3299 - val_loss: 1.8497\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 121ms/step - accuracy: 0.3113 - loss: 1.8921 - val_accuracy: 0.3278 - val_loss: 1.8519\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 113ms/step - accuracy: 0.3097 - loss: 1.9007 - val_accuracy: 0.3355 - val_loss: 1.8367\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 123ms/step - accuracy: 0.3113 - loss: 1.8970 - val_accuracy: 0.3377 - val_loss: 1.8343\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo con data augmentation\n",
    "history = model.fit(datagen.flow(train_images, train_labels, batch_size=64),\n",
    "                    epochs=10,\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e11dc4-c23e-4430-83f1-2ab4b8b84c49",
   "metadata": {},
   "source": [
    "**Paso 5: Evaluar el modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b83661bb-5fbf-4aa8-a742-6af395b8cb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 64ms/step - accuracy: 0.3384 - loss: 1.8315\n",
      "Accuracy en test: 0.3377000093460083\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el set de test\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Accuracy en test: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c9310b-f427-4a83-a2fa-879ac2ad3387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
