{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6bd7479-1a35-4f97-83c1-84026decffd0",
   "metadata": {},
   "source": [
    "### **1. Normalización y Estandarización**\n",
    "\n",
    "#### **Normalización**\n",
    "- **¿Qué es?**: Escala los valores de las características para que estén dentro de un rango específico, típicamente entre 0 y 1.\n",
    "- **¿Cuándo usarla?**: Útil cuando los datos tienen distribuciones que varían ampliamente en escala o cuando los modelos de machine learning son sensibles a la magnitud de los datos (por ejemplo, redes neuronales y SVM).\n",
    "- **Método**: Min-Max Scaling.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "```\n",
    "\n",
    "#### **Estandarización**\n",
    "- **¿Qué es?**: Transforma los datos para que tengan una media de 0 y una desviación estándar de 1.\n",
    "- **¿Cuándo usarla?**: Útil cuando las características tienen distribuciones gaussianas o cuando se aplican algoritmos sensibles a la escala de los datos, como regresión logística o SVM.\n",
    "- **Método**: Z-score scaling.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecf6d86-f568-4183-91ed-32539ba1c871",
   "metadata": {},
   "source": [
    "### **2. Selección de Características**\n",
    "\n",
    "#### **Selección Basada en Varianza**\n",
    "- **Qué es?**: Elimina características que tienen muy poca varianza, es decir, que no aportan mucha información.\n",
    "- **Cuándo usarla?**: Cuando se tienen muchas características que pueden no ser útiles o ser redundantes.\n",
    "  \n",
    "```python\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.1)\n",
    "X_selected = selector.fit_transform(X)\n",
    "```\n",
    "\n",
    "\n",
    "#### **Selección Basada en Importancia de Características**\n",
    "- **¿Qué es?**: Utiliza algoritmos como Random Forest o árboles de decisión para calcular la importancia de cada característica, y elimina las que son menos relevantes.\n",
    "- **¿Cuándo usarla?**: En datasets con muchas características donde se busca reducir dimensionalidad basada en importancia.\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "importances = model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ada1d-23da-4c7b-8f0a-42bfc624d7f7",
   "metadata": {},
   "source": [
    "### **3. Transformaciones de Características**\n",
    "\n",
    "#### **Transformación Logarítmica**\n",
    "- **¿Qué es?**: Aplica una transformación logarítmica a las características para reducir el sesgo y las grandes diferencias entre valores.\n",
    "- **¿Cuándo usarla?**: Cuando los datos tienen una distribución sesgada y se desea normalizarlos.\n",
    "  \n",
    "```python\n",
    "import numpy as np\n",
    "X_transformed = np.log(X + 1)\n",
    "```\n",
    "\n",
    "#### **Transformación de Potencia (Power Transform)**\n",
    "- **¿Qué es?**: Aplica una transformación no lineal para hacer que los datos se parezcan más a una distribución normal.\n",
    "- **¿Cuándo usarla?**: Cuando los datos tienen una gran asimetría o valores extremos.\n",
    "  \n",
    "```python\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "pt = PowerTransformer()\n",
    "X_power_transformed = pt.fit_transform(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40a6210-efb3-4dd9-8e28-7e55e263b60a",
   "metadata": {},
   "source": [
    "### **4. Técnicas de Imputación de Datos Faltantes**\n",
    "\n",
    "#### **Imputación Simple**\n",
    "- **¿Qué es?**: Rellena los valores faltantes con la media, mediana o moda de los datos.\n",
    "- **¿Cuándo usarla?**: Cuando tienes datos faltantes en algunas columnas pero la mayoría de las observaciones están presentes.\n",
    "\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "```\n",
    "\n",
    "#### **K-Nearest Neighbors Imputation**\n",
    "- **¿Qué es?**: Usa los valores de los vecinos más cercanos para imputar los datos faltantes.\n",
    "- **¿Cuándo usarla?**: Cuando los datos faltantes dependen de la estructura de los otros valores en el dataset.\n",
    "  \n",
    "```python\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_imputed_knn = imputer.fit_transform(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc62267c-c381-4b1f-ab0b-d75c77933ddb",
   "metadata": {},
   "source": [
    "### **5. Generación de Nuevas Características**\n",
    "\n",
    "#### **Análisis de Componentes Independientes (ICA)**\n",
    "- **¿Qué es?**: Similar a PCA, pero busca encontrar componentes que sean estadísticamente independientes entre sí.\n",
    "- **¿Cuándo usarla?**: Cuando tienes señales mezcladas y deseas separar las fuentes de forma independiente.\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import FastICA\n",
    "ica = FastICA(n_components=2)\n",
    "X_ica = ica.fit_transform(X)\n",
    "```\n",
    "\n",
    "#### **Polinomios (Polynomial Features)**\n",
    "- **¿Qué es?**: Genera nuevas características que son combinaciones polinómicas de las características originales.\n",
    "- **¿Cuándo usarla?**: Cuando se cree que las relaciones entre las características no son lineales.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9546a5a2-5763-4aa1-b760-7ce26b2634ce",
   "metadata": {},
   "source": [
    "### **6. Filtrado de Datos Ruidosos y Atípicos (Outliers)**\n",
    "\n",
    "#### **Eliminación de Outliers con IQR (Interquartile Range)**\n",
    "- **¿Qué es?**: Elimina valores atípicos que están fuera del rango intercuartil (IQR).\n",
    "- **¿Cuándo usarla?**: Cuando tienes valores extremos que pueden sesgar tu modelo.\n",
    "\n",
    "```python\n",
    "Q1 = X.quantile(0.25)\n",
    "Q3 = X.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "X_filtered = X[~((X < (Q1 - 1.5 * IQR)) | (X > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c4b3c6-c509-4044-bc97-abefe0bfb90b",
   "metadata": {},
   "source": [
    "### **7. Técnicas Avanzadas de Reducción de Dimensionalidad**\n",
    "\n",
    "#### **t-SNE (t-distributed Stochastic Neighbor Embedding)**\n",
    "- **¿Qué es?**: Técnica no lineal de reducción de dimensionalidad que mantiene las relaciones locales en los datos.\n",
    "- **¿Cuándo usarla?**: Para visualizar datos de alta dimensionalidad en 2D o 3D, particularmente útil en clustering o análisis de datos complejos.\n",
    "\n",
    "```python\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "```\n",
    "\n",
    "#### **UMAP (Uniform Manifold Approximation and Projection)**\n",
    "- **¿Qué es?**: Una técnica de reducción de dimensionalidad similar a t-SNE pero más rápida, especialmente para conjuntos de datos grandes.\n",
    "- **¿Cuándo usarla?**: En visualización o para encontrar relaciones complejas en los datos.\n",
    "\n",
    "```python\n",
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "X_umap = reducer.fit_transform(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d27b6-76cb-4bf5-8f41-62356b4f03be",
   "metadata": {},
   "source": [
    "\n",
    "### **Resumen**\n",
    "\n",
    "- **PCA** y **suavizado (smoothness)** son solo dos de los muchos métodos disponibles para preparar datos. En el contexto de la ciencia de datos y machine learning, preparar adecuadamente los datos es un paso crucial para mejorar la precisión y la eficiencia del modelo. Estos dos enfoques se pueden complementar con otros métodos como **normalización**, **selección de características** y **transformaciones**, que ayudan a mejorar la calidad del conjunto de datos en distintos aspectos.\n",
    "  \n",
    "- **PCA** es muy efectivo cuando se desea reducir la dimensionalidad de un dataset manteniendo la mayor cantidad de información posible. Sin embargo, es importante recordar que **PCA** solo se basa en la varianza, y si hay ruido en los datos, puede reducir la eficacia de los componentes principales generados.\n",
    "\n",
    "- **El suavizado** es útil para eliminar el ruido, lo que puede ayudar a evitar el sobreajuste de los modelos a los datos. Métodos como el **suavizado exponencial** o **filtros de medias móviles** son comúnmente utilizados en el procesamiento de datos secuenciales o cuando hay fluctuaciones inesperadas.\n",
    "\n",
    "- Otros métodos como la **normalización** o **estandarización** son esenciales para ajustar las escalas de los datos, algo que mejora el rendimiento de modelos basados en distancia, como **KNN** o **SVM**. Las técnicas avanzadas de reducción de dimensionalidad como **t-SNE** y **UMAP** permiten explorar patrones ocultos en los datos cuando hay muchas características.\n",
    "\n",
    "En general, la elección de las técnicas dependerá del tipo de datos con los que trabajas y los objetivos del análisis o el modelo de machine learning que estés utilizando. Algunos métodos pueden ser más efectivos en ciertos casos, por lo que es común combinarlos para obtener los mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e201f5b-e8fe-4291-8cbe-6ff108f6a075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
